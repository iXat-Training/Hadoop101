<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Hadoop101 by iXat-Training</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Hadoop101</h1>
      <h2 class="project-tagline">BigData Hadoop Training for 101 batch, KPHB Hyderabad -  ixatsolutions@gmai.com/9703143000</h2>
      <a href="https://github.com/iXat-Training/Hadoop101" class="btn">View on GitHub</a>
      <a href="https://github.com/iXat-Training/Hadoop101/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/iXat-Training/Hadoop101/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="hadoop-examples-that-were-built-and-demoed-in-the-ixat-hadoop-training-course" class="anchor" href="#hadoop-examples-that-were-built-and-demoed-in-the-ixat-hadoop-training-course" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hadoop examples that were built and demoed in the IXAT Hadoop training course..</h1>

<p><strong>Code/Reference samples are as the below. Please note that the course is still in progress, visit again to see updated content.</strong></p>

<ul>
<li>### Building Hadoop on windows, the required steps and softwares are elobarated in the readme.txt of the subfolder.</li>
<li>### HDFS Examples on a Windows Pseudo-Dist Hadoop Node<br>
</li>
<li>### Maven based Java client for reading off an HDFS running in a VBox-CentOS based Hadoop Pseudo-Dist node</li>
<li>### A Maven project for analyzing stock trades that have happened on given set of stocks data (live from Google finance), the application also demonstrates how to use maven for building a Hadoop Job Jar.</li>
<li>### Yarn theory and demonstration of a non-MR application on a YARN cluster</li>
<li>### Application to demonstrate JobChaining, ToolRunner and Custom Counters<br>
</li>
<li>### Deriving an InvertedIndex on StackOverflow posts and different types of Joins</li>
<li>### Some assignments for the weekend :-)</li>
<li>### Samples to demonstrates inputformats and custom input format to read from XML HDFS input</li>
<li>### Pig Intro and a Pig Reference </li>
<li>### Pig examples with params, projection, grouping and Joins<br>
</li>
<li>### Pig UDF to extract weekday from a string date, extension to our stock data</li>
<li>### Hive intro, setup, create table, sort and grouping</li>
<li>### Hive samples with dynamic partition examples.</li>
<li>### UDF in Hive<br>
</li>
<li>### Apache drill intro and samples queries, used Tableu for visualization</li>
<li>### Flume Intro, demonstration of sample sources, sinks and types of channels/</li>
<li>### Assignment on Twitter sentiment analytics using Twitter4J, Flume, HDFS, Drill, Stanford NLP. </li>
<li>### * Created a custom source, this is your starting point.
    -Store the Twitter feeds partitioned by Date and Hour in HDFS, a sample Flume Twitter Source is provided for your reference. 
-Twitter content is usually an OR of keywords provided in the FilterQuery, derive a logical AND of tweets on the provided keywords
-Twitter content over a period of time can result in multiple small files in HDFS, All historical Twitter (Current Day - 1) feeds need to be consolidated a bigger files (of size 64MB) and stored in HDFS.
-Do a sentiment analysis of Tweets using Stanford NLP (example provided)
-Generate a Timeseries graph (or a scatter) in Tableu on the sentiment score and with count of tweets.
-Write a utility which would take hour of the day as input and displays all the possible sentiment scores and #count of tweets for that hour. When given a sentiment score and hour, the utility should fetch all originall tweets which fall in this criteria.
-Use Tableu for visualization.</li>
<li>### Avro introduction, demonstrate projection and evolution. Also, there is a C# test which reads off an avro file generated from java</li>
</ul>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/iXat-Training/Hadoop101">Hadoop101</a> is maintained by <a href="https://github.com/iXat-Training">iXat-Training</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
