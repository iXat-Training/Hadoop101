<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Hadoop101 by iXat-Training</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Hadoop101</h1>
      <h2 class="project-tagline">BigData Hadoop Training for 101 batch, KPHB Hyderabad -  ixatsolutions@gmail.com/9703143000</h2>
      <a href="https://github.com/iXat-Training/Hadoop101" class="btn">View on GitHub</a>
      <a href="https://github.com/iXat-Training/Hadoop101/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/iXat-Training/Hadoop101/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="hadoop-code-examples-that-were-built-and-demoed-in-hadoop-training--ixat-kphb-kukatpally-hyderabad" class="anchor" href="#hadoop-code-examples-that-were-built-and-demoed-in-hadoop-training--ixat-kphb-kukatpally-hyderabad" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hadoop code examples that were built and demoed in Hadoop training @ iXat, KPHB, Kukatpally, Hyderabad.</h1>

<p><em>Code/Reference samples are as the below. Please note that the course is still in progress, visit again to see updated content.</em></p>

<ul>
<li><h3>
<a id="building-hadoop-on-windows-the-required-steps-and-softwares-are-elobarated-in-the-readme" class="anchor" href="#building-hadoop-on-windows-the-required-steps-and-softwares-are-elobarated-in-the-readme" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building Hadoop on windows, the required steps and softwares are elobarated in the readme.</h3></li>
<li><h3>
<a id="hdfs-examples-on-a-windows-hadoop-node" class="anchor" href="#hdfs-examples-on-a-windows-hadoop-node" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>HDFS Examples on a Windows Hadoop Node</h3></li>
<li><h3>
<a id="maven-based-java-client-for-reading-off-an-hdfs-running-in-a-vbox-centos-based-hadoop-pseudo-dist-node" class="anchor" href="#maven-based-java-client-for-reading-off-an-hdfs-running-in-a-vbox-centos-based-hadoop-pseudo-dist-node" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Maven based Java client for reading off an HDFS running in a VBox-CentOS based Hadoop Pseudo-Dist node</h3></li>
<li><h3>
<a id="a-maven-project-for-analyzing-stock-trades-that-have-happened-on-given-set-of-stocks-data-live-from-google-finance-the-application-also-demonstrates-how-to-use-maven-for-building-a-hadoop-job-jar" class="anchor" href="#a-maven-project-for-analyzing-stock-trades-that-have-happened-on-given-set-of-stocks-data-live-from-google-finance-the-application-also-demonstrates-how-to-use-maven-for-building-a-hadoop-job-jar" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>A Maven project for analyzing stock trades that have happened on given set of stocks data (live from Google finance), the application also demonstrates how to use maven for building a Hadoop Job Jar.</h3></li>
<li><h3>
<a id="yarn-theory-and-demonstration-of-a-non-mr-application-on-a-yarn-cluster" class="anchor" href="#yarn-theory-and-demonstration-of-a-non-mr-application-on-a-yarn-cluster" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Yarn theory and demonstration of a non-MR application on a YARN cluster</h3></li>
<li><h3>
<a id="application-to-demonstrate-jobchaining-toolrunner-and-custom-counters" class="anchor" href="#application-to-demonstrate-jobchaining-toolrunner-and-custom-counters" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Application to demonstrate JobChaining, ToolRunner and Custom Counters</h3></li>
<li><h3>
<a id="deriving-an-invertedindex-on-stackoverflow-posts-and-different-types-of-joins" class="anchor" href="#deriving-an-invertedindex-on-stackoverflow-posts-and-different-types-of-joins" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deriving an InvertedIndex on StackOverflow posts and different types of Joins</h3></li>
<li><h3>
<a id="some-assignments-for-the-weekend--" class="anchor" href="#some-assignments-for-the-weekend--" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Some assignments for the weekend :-)</h3></li>
<li><h3>
<a id="samples-to-demonstrates-inputformats-and-custom-input-format-to-read-from-xml-hdfs-input" class="anchor" href="#samples-to-demonstrates-inputformats-and-custom-input-format-to-read-from-xml-hdfs-input" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Samples to demonstrates inputformats and custom input format to read from XML HDFS input</h3></li>
<li><h3>
<a id="pig-intro-and-a-pig-reference" class="anchor" href="#pig-intro-and-a-pig-reference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pig Intro and a Pig Reference</h3></li>
<li><h3>
<a id="pig-examples-with-params-projection-grouping-and-joins" class="anchor" href="#pig-examples-with-params-projection-grouping-and-joins" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pig examples with params, projection, grouping and Joins</h3></li>
<li><h3>
<a id="pig-udf-to-extract-weekday-from-a-string-date-extension-to-our-stock-data" class="anchor" href="#pig-udf-to-extract-weekday-from-a-string-date-extension-to-our-stock-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pig UDF to extract weekday from a string date, extension to our stock data</h3></li>
<li><h3>
<a id="hive-intro-setup-create-table-sort-and-grouping" class="anchor" href="#hive-intro-setup-create-table-sort-and-grouping" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hive intro, setup, create table, sort and grouping</h3></li>
<li><h3>
<a id="hive-samples-with-dynamic-partition-examples" class="anchor" href="#hive-samples-with-dynamic-partition-examples" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hive samples with dynamic partition examples.</h3></li>
<li><h3>
<a id="udf-in-hive" class="anchor" href="#udf-in-hive" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>UDF in Hive</h3></li>
<li><h3>
<a id="apache-drill-intro-and-samples-queries-used-tableu-for-visualization" class="anchor" href="#apache-drill-intro-and-samples-queries-used-tableu-for-visualization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Apache drill intro and samples queries, used Tableu for visualization</h3></li>
<li><h3>
<a id="flume-intro" class="anchor" href="#flume-intro" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Flume Intro</h3></li>
<li>
<h3>
<a id="assignment-on-twitter-sentiment-analytics-using-twitter4j-flume-hdfs-drill-stanford-nlp" class="anchor" href="#assignment-on-twitter-sentiment-analytics-using-twitter4j-flume-hdfs-drill-stanford-nlp" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Assignment on Twitter sentiment analytics using Twitter4J, Flume, HDFS, Drill, Stanford NLP.</h3>

<p>1 ### Store the Twitter feeds partitioned by Date and Hour in HDFS, a sample Flume Twitter Source is provided for your reference. </p>

<p>2 ### Twitter content is usually an OR of keywords provided in the FilterQuery, derive a logical AND of tweets on the provided keywords</p>

<p>3 ### Twitter content over a period of time can result in multiple small files in HDFS, All historical Twitter (Current Day - 1) feeds need to be consolidated a bigger files (of size 64MB) and stored in HDFS.</p>

<p>4 ### Do a sentiment analysis of Tweets using Stanford NLP (example provided)</p>

<p>5 ### Generate a Timeseries graph (or a scatter) in Tableu on the sentiment score and with count of tweets.</p>

<p>6 ### Write a utility which would take hour of the day as input and displays all the possible sentiment scores and #count of tweets for that hour. When given a sentiment score and hour, the utility should fetch all originall tweets which fall in this criteria.</p>

<p>7 ### Use Tableu for visualization.</p>
</li>
<li><h3>
<a id="avro-introduction-demonstrate-projection-and-evolution-also-there-is-a-c-test-which-reads-off-an-avro-file-generated-from-java" class="anchor" href="#avro-introduction-demonstrate-projection-and-evolution-also-there-is-a-c-test-which-reads-off-an-avro-file-generated-from-java" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Avro introduction, demonstrate projection and evolution. Also, there is a C# test which reads off an avro file generated from java</h3></li>
<li>
<h3>
<a id="zookeeper-samples-using-a-quorum-with-watchers-also-there-is-a-sample-which-uses-curator-fw-for-zookeeper" class="anchor" href="#zookeeper-samples-using-a-quorum-with-watchers-also-there-is-a-sample-which-uses-curator-fw-for-zookeeper" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ZooKeeper samples, using a quorum with watchers. Also, there is a sample which uses Curator f/w for Zookeeper.</h3>

<p>1 A Zookeeper Client with watcher</p>

<p>2 Zookeeper Client for a Quorum</p>

<p>3 Curator sample</p>

<p>4 NodeJS application to set watch and set data in a quorum</p>
</li>
<li>
<h3>
<a id="kafka-samples-introduction-to-kafka-and-c-and-java" class="anchor" href="#kafka-samples-introduction-to-kafka-and-c-and-java" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Kafka samples, Introduction to Kafka and C# and Java.</h3>

<p>1 Kafka Intro</p>

<p>2 How Kafka scales and is more durable than other messaging models</p>

<p>3 Topics, Partitions and Replication</p>

<p>4 Running a single broker</p>

<p>5 Multiple brokers in action</p>

<p>6 A C# Kafka producer in action</p>

<p>7 Java Kafka producer and consumers in action</p>

<p>Best Hadoop training in Hyderabad - IXAT Solutions, Kukatpally, Hyderabad 2016</p>
</li>
</ul>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/iXat-Training/Hadoop101">Hadoop101</a> is maintained by <a href="https://github.com/iXat-Training">iXat-Training</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

            <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-72613811-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>
